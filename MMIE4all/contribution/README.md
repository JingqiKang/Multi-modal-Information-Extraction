# Multi-modal Information Extraction Literature 
This repository is maintained by [Tongtong Wu](http://wutong8023.site/) and [Jingqi Kang](https://#####). 

The automation script of this repo is powered by [Auto-Bibfile](https://github.com/wutong8023/Auto-Bibfile.git).

You can directly use our bibtex.bib in overleaf with this [link](https://www.overleaf.com/read/gszxbvbkprfs).

This page categorizes the literature by the Contribution.

## Outline 
- [![](https://img.shields.io/badge/Hyperlink-blue)](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/contribution\README.md#hyperlink)
- [![](https://img.shields.io/badge/Survey-1-blue)](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/contribution\README.md#survey)
- [![](https://img.shields.io/badge/New_Task-3-blue)](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/contribution\README.md#new-task)
## Hyperlink 
- [[Overview]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//README.md) -- [Homepage](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//README.md)
- [[NLP]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4nlp/./)  [[CV]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4cv/./) -- [Summary](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/./)
- [[NLP]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4nlp/application)  [[CV]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4cv/application) -- [Application](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/application)
- [[NLP]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4nlp/approach)  [[CV]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4cv/approach) -- [Approach](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/approach)
- [[NLP]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4nlp/author)  [[CV]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4cv/author) -- [Author](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/author)
- [[NLP]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4nlp/backbone_model)  [[CV]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4cv/backbone_model) -- [Backbone Model](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/backbone_model)
- [[NLP]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4nlp/contribution)  [[CV]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4cv/contribution) -- [Contribution](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/contribution)
- [[NLP]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4nlp/dataset)  [[CV]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4cv/dataset) -- [Dataset](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/dataset)
- [[NLP]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4nlp/metrics)  [[CV]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4cv/metrics) -- [Metrics](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/metrics)
- [[NLP]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4nlp/research_question)  [[CV]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4cv/research_question) -- [Research Questions](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/research_question)
- [[NLP]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4nlp/setting)  [[CV]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4cv/setting) -- [Setting](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/setting)
- [[NLP]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4nlp/supervision)  [[CV]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4cv/supervision) -- [ Learning Paradigm](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/supervision)
- [[NLP]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4nlp/time)  [[CV]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4cv/time) -- [Published Time](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/time)
- [[NLP]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4nlp/venue)  [[CV]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4cv/venue) -- [Published Venue](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//MMIE4all/venue)

## Survey

- [![](https://img.shields.io/badge/Applied_Sciences-2022-blue)](https://www.mdpi.com/2076-3417/12/4/2204) [**A Survey of Data Representation for Multi-Modality Event Detection and Evolution**](https://www.mdpi.com/2076-3417/12/4/2204) , <br> by *Xiao, Kejing, Qian, Zhaopeng and Qin, Biao* [[bib]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//./bibtex.bib#L60-L67)<br> </details><details><summary><img src=https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//scripts/svg/copy_icon.png height="20"></summary><pre>```Xiao_2022_Survey```
## New Task

- [![](https://img.shields.io/badge/EMNLP-2021-blue)](https://aclanthology.org/2021.findings-emnlp.8) [**Joint Multimedia Event Extraction from Video and Article**](https://aclanthology.org/2021.findings-emnlp.8) , <br> by *Chen, Brian  and
Lin, Xudong  and
Thomas, Christopher  and
Li, Manling  and
Yoshida, Shoya  and
Chum, Lovish  and
Ji, Heng  and
Chang, Shih-Fu* [[bib]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//./bibtex.bib#L30-L45)<br> ```This paper proposes a new task of video multimodal event extraction
```</details><details><summary><img src=https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//scripts/svg/copy_icon.png height="20"></summary><pre>```chen-etal-2021-joint-multimedia-event```
- [![](https://img.shields.io/badge/ACL-2020-blue)](https://aclanthology.org/2020.acl-main.230) [**Cross-media Structured Common Space for Multimedia Event Extraction**](https://aclanthology.org/2020.acl-main.230) , <br> by *Li, Manling  and
Zareian, Alireza  and
Zeng, Qi  and
Whitehead, Spencer  and
Lu, Di  and
Ji, Heng  and
Chang, Shih-Fu* [[bib]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//./bibtex.bib#L13-L27)<br> ```The first paper to define a multimodal event extraction task
```</details><details><summary><img src=https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//scripts/svg/copy_icon.png height="20"></summary><pre>```li-etal-2020-cross```
- [![](https://img.shields.io/badge/MM-2017-blue)](https://doi.org/10.1145/3123266.3123294) [**Improving Event Extraction via Multimodal Integration**](https://doi.org/10.1145/3123266.3123294) , <br> by *Zhang, Tongtao, Whitehead, Spencer, Zhang, Hanwang, Li, Hongzhi, Ellis, Joseph, Huang, Lifu, Liu, Wei, Ji, Heng and Chang, Shih-Fu* [[bib]](https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//./bibtex.bib#L2-L10)<br> ```The first paper to do multimodal event extraction
```</details><details><summary><img src=https://github.com/JingqiKang/Multi-modal-Information-Extraction/blob/main//scripts/svg/copy_icon.png height="20"></summary><pre>```Zhang_VAD_2017```